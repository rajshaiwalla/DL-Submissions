{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "J043_DL_Test_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajshaiwalla/DL-Submissions/blob/master/J043_DL_Test_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k7_6os568rX",
        "colab_type": "text"
      },
      "source": [
        "##Raj Shaiwalla, J043: Test 1\n",
        "BTech Data Science Third Year"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyS2_gJbvNBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEQg-n3WwCXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7H4seB9wETJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Categorically encode labels\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgZBluTPwFat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePwqr0hAxaxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya5JgbGIxeI2",
        "colab_type": "code",
        "outputId": "e15cebec-7ca9-455c-8d3a-fcb7bd13c667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.2285 - acc: 0.9307 - val_loss: 0.1061 - val_acc: 0.9660\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0829 - acc: 0.9743 - val_loss: 0.0803 - val_acc: 0.9751\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0541 - acc: 0.9831 - val_loss: 0.0677 - val_acc: 0.9800\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0395 - acc: 0.9878 - val_loss: 0.0681 - val_acc: 0.9825\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0280 - acc: 0.9911 - val_loss: 0.0714 - val_acc: 0.9819\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0228 - acc: 0.9930 - val_loss: 0.0879 - val_acc: 0.9796\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0188 - acc: 0.9941 - val_loss: 0.0963 - val_acc: 0.9803\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0147 - acc: 0.9953 - val_loss: 0.0845 - val_acc: 0.9821\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0121 - acc: 0.9964 - val_loss: 0.1145 - val_acc: 0.9775\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0103 - acc: 0.9969 - val_loss: 0.1072 - val_acc: 0.9824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f745ef1a4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsImmn3Sxga4",
        "colab_type": "code",
        "outputId": "6ab003ee-9961-4d64-dc0d-fa36b81642fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.10715986683762845\n",
            "Test accuracy: 0.9824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG7NY4KExzeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "sgd=keras.optimizers.SGD(lr=0.01, momentum=0.0, nesterov=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR85dOWX2KVV",
        "colab_type": "code",
        "outputId": "935b8641-a53c-4b03-d09b-1b4c640abc49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0041 - acc: 0.9986 - val_loss: 0.0956 - val_acc: 0.9835\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0935 - val_acc: 0.9834\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0922 - val_acc: 0.9836\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0913 - val_acc: 0.9838\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0013 - acc: 0.9998 - val_loss: 0.0906 - val_acc: 0.9839\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0900 - val_acc: 0.9839\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 0.0010 - acc: 0.9999 - val_loss: 0.0895 - val_acc: 0.9839\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 9.7411e-04 - acc: 0.9999 - val_loss: 0.0891 - val_acc: 0.9840\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 9.1581e-04 - acc: 0.9999 - val_loss: 0.0887 - val_acc: 0.9840\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 8.6829e-04 - acc: 0.9999 - val_loss: 0.0884 - val_acc: 0.9840\n",
            "Test loss: 0.08841139053898407\n",
            "Test accuracy: 0.984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkwfC4QQ2L1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "rms=keras.optimizers.RMSprop(lr=0.001, rho=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zErZfP1O2RtW",
        "colab_type": "code",
        "outputId": "9483bd0f-0830-41c9-ef8f-08e6a3d4cf26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=rms,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0110 - acc: 0.9965 - val_loss: 0.1064 - val_acc: 0.9826\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0087 - acc: 0.9975 - val_loss: 0.1074 - val_acc: 0.9824\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0074 - acc: 0.9978 - val_loss: 0.1324 - val_acc: 0.9780\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0082 - acc: 0.9979 - val_loss: 0.1091 - val_acc: 0.9824\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0074 - acc: 0.9981 - val_loss: 0.1333 - val_acc: 0.9822\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0056 - acc: 0.9984 - val_loss: 0.1298 - val_acc: 0.9812\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0050 - acc: 0.9986 - val_loss: 0.1196 - val_acc: 0.9834\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0055 - acc: 0.9986 - val_loss: 0.1241 - val_acc: 0.9826\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0048 - acc: 0.9987 - val_loss: 0.1412 - val_acc: 0.9819\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0038 - acc: 0.9989 - val_loss: 0.1324 - val_acc: 0.9835\n",
            "Test loss: 0.13241278107824886\n",
            "Test accuracy: 0.9835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ2O48p02SvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "ada=keras.optimizers.Adagrad(lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjd3iUUG2U-s",
        "colab_type": "code",
        "outputId": "d8d9e59c-4380-4e58-e958-b26b665b26eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=ada,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0241 - acc: 0.9961 - val_loss: 0.1151 - val_acc: 0.9837\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 9.4771e-04 - acc: 0.9998 - val_loss: 0.1113 - val_acc: 0.9844\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 3.3966e-04 - acc: 1.0000 - val_loss: 0.1098 - val_acc: 0.9851\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 2.9066e-04 - acc: 1.0000 - val_loss: 0.1097 - val_acc: 0.9851\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.8707e-04 - acc: 1.0000 - val_loss: 0.1097 - val_acc: 0.9851\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.8497e-04 - acc: 1.0000 - val_loss: 0.1097 - val_acc: 0.9852\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 2.8348e-04 - acc: 1.0000 - val_loss: 0.1098 - val_acc: 0.9852\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 2.8232e-04 - acc: 1.0000 - val_loss: 0.1098 - val_acc: 0.9851\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.8139e-04 - acc: 1.0000 - val_loss: 0.1098 - val_acc: 0.9851\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 2.8062e-04 - acc: 1.0000 - val_loss: 0.1099 - val_acc: 0.9851\n",
            "Test loss: 0.10985813669308148\n",
            "Test accuracy: 0.9851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0siIJN_2WLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adelta=keras.optimizers.Adadelta(lr=1.0, rho=0.95)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P52I7NVD2Z2N",
        "colab_type": "code",
        "outputId": "1d73bfd8-e3f8-431f-e4b5-034f3b5d2b40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adelta,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 2.7993e-04 - acc: 1.0000 - val_loss: 0.1101 - val_acc: 0.9849\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 2.7837e-04 - acc: 1.0000 - val_loss: 0.1101 - val_acc: 0.9850\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 2.7730e-04 - acc: 1.0000 - val_loss: 0.1103 - val_acc: 0.9850\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 2.7649e-04 - acc: 1.0000 - val_loss: 0.1103 - val_acc: 0.9851\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.7587e-04 - acc: 1.0000 - val_loss: 0.1104 - val_acc: 0.9850\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 2.7536e-04 - acc: 1.0000 - val_loss: 0.1104 - val_acc: 0.9851\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 2.7493e-04 - acc: 1.0000 - val_loss: 0.1105 - val_acc: 0.9851\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.7457e-04 - acc: 1.0000 - val_loss: 0.1106 - val_acc: 0.9851\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 2.7425e-04 - acc: 1.0000 - val_loss: 0.1106 - val_acc: 0.9851\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 2.7397e-04 - acc: 1.0000 - val_loss: 0.1107 - val_acc: 0.9850\n",
            "Test loss: 0.11068925892773925\n",
            "Test accuracy: 0.985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSWuLFd22bRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-piKnWXC2cpJ",
        "colab_type": "code",
        "outputId": "940e08d7-47e2-4894-f94a-6c84fea06437",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.0214 - acc: 0.9947 - val_loss: 0.1258 - val_acc: 0.9803\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0113 - acc: 0.9968 - val_loss: 0.1308 - val_acc: 0.9807\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0106 - acc: 0.9973 - val_loss: 0.1184 - val_acc: 0.9799\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0125 - acc: 0.9966 - val_loss: 0.0942 - val_acc: 0.9825\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0118 - acc: 0.9967 - val_loss: 0.1059 - val_acc: 0.9820\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0072 - acc: 0.9980 - val_loss: 0.1156 - val_acc: 0.9802\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0091 - acc: 0.9975 - val_loss: 0.1399 - val_acc: 0.9786\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0088 - acc: 0.9975 - val_loss: 0.1339 - val_acc: 0.9788\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0121 - acc: 0.9967 - val_loss: 0.1049 - val_acc: 0.9827\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0092 - acc: 0.9974 - val_loss: 0.1163 - val_acc: 0.9808\n",
            "Test loss: 0.11625469246726093\n",
            "Test accuracy: 0.9808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1uH7XZO2h79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "nadam=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLm5wKw12jwH",
        "colab_type": "code",
        "outputId": "af660df7-8823-4e67-f10e-0ded2d1998e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=nadam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.0356 - acc: 0.9923 - val_loss: 0.1891 - val_acc: 0.9707\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0223 - acc: 0.9942 - val_loss: 0.1122 - val_acc: 0.9809\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0155 - acc: 0.9958 - val_loss: 0.1079 - val_acc: 0.9811\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0195 - acc: 0.9948 - val_loss: 0.1318 - val_acc: 0.9781\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0164 - acc: 0.9955 - val_loss: 0.1137 - val_acc: 0.9792\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0225 - acc: 0.9939 - val_loss: 0.1316 - val_acc: 0.9775\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0187 - acc: 0.9950 - val_loss: 0.1297 - val_acc: 0.9771\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0147 - acc: 0.9958 - val_loss: 0.1072 - val_acc: 0.9821\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0175 - acc: 0.9953 - val_loss: 0.1091 - val_acc: 0.9797\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0159 - acc: 0.9954 - val_loss: 0.1203 - val_acc: 0.9787\n",
            "Test loss: 0.12033943312886763\n",
            "Test accuracy: 0.9787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMpzVB7K2lgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG4so5lh4sw5",
        "colab_type": "code",
        "outputId": "b9198c9b-f5e1-4397-eaba-a23ff7fdc653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adamax,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0969 - val_acc: 0.9835\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 4.3362e-04 - acc: 1.0000 - val_loss: 0.0965 - val_acc: 0.9847\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 3.4358e-04 - acc: 1.0000 - val_loss: 0.0974 - val_acc: 0.9847\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 3.1712e-04 - acc: 1.0000 - val_loss: 0.0982 - val_acc: 0.9845\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 3.0054e-04 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9847\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.8934e-04 - acc: 1.0000 - val_loss: 0.1010 - val_acc: 0.9848\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.8163e-04 - acc: 1.0000 - val_loss: 0.1025 - val_acc: 0.9849\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 2.7655e-04 - acc: 1.0000 - val_loss: 0.1037 - val_acc: 0.9854\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 2.7345e-04 - acc: 1.0000 - val_loss: 0.1051 - val_acc: 0.9856\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 2.7158e-04 - acc: 1.0000 - val_loss: 0.1067 - val_acc: 0.9858\n",
            "Test loss: 0.10666864179977895\n",
            "Test accuracy: 0.9858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtwcZGOF9mpR",
        "colab_type": "code",
        "outputId": "583c3138-c0d9-4207-bfd4-3a83747f685c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_dARhw94sp-",
        "colab_type": "code",
        "outputId": "765b81b0-689a-40ee-a9a3-99b54d1e1dc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJrRqmzK5GH4",
        "colab_type": "code",
        "outputId": "fcdc1484-49b3-46d4-e0dc-dee2cd1b9e76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "source": [
        "# Output network visualization\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"352pt\" viewBox=\"0.00 0.00 181.00 264.00\" width=\"241pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 260)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-260 177,-260 177,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140137786044088 -->\n<g class=\"node\" id=\"node1\">\n<title>140137786044088</title>\n<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 173,-255.5 173,-219.5 0,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-233.8\">dense_4_input: InputLayer</text>\n</g>\n<!-- 140137787497608 -->\n<g class=\"node\" id=\"node2\">\n<title>140137787497608</title>\n<polygon fill=\"none\" points=\"33,-146.5 33,-182.5 140,-182.5 140,-146.5 33,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-160.8\">dense_4: Dense</text>\n</g>\n<!-- 140137786044088&#45;&gt;140137787497608 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140137786044088-&gt;140137787497608</title>\n<path d=\"M86.5,-219.4551C86.5,-211.3828 86.5,-201.6764 86.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-192.5903 86.5,-182.5904 83.0001,-192.5904 90.0001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140137787497160 -->\n<g class=\"node\" id=\"node3\">\n<title>140137787497160</title>\n<polygon fill=\"none\" points=\"33,-73.5 33,-109.5 140,-109.5 140,-73.5 33,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-87.8\">dense_5: Dense</text>\n</g>\n<!-- 140137787497608&#45;&gt;140137787497160 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140137787497608-&gt;140137787497160</title>\n<path d=\"M86.5,-146.4551C86.5,-138.3828 86.5,-128.6764 86.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-119.5903 86.5,-109.5904 83.0001,-119.5904 90.0001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140137786162872 -->\n<g class=\"node\" id=\"node4\">\n<title>140137786162872</title>\n<polygon fill=\"none\" points=\"33,-.5 33,-36.5 140,-36.5 140,-.5 33,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-14.8\">dense_6: Dense</text>\n</g>\n<!-- 140137787497160&#45;&gt;140137786162872 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140137787497160-&gt;140137786162872</title>\n<path d=\"M86.5,-73.4551C86.5,-65.3828 86.5,-55.6764 86.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-46.5903 86.5,-36.5904 83.0001,-46.5904 90.0001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    }
  ]
}